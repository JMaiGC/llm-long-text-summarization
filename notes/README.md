# NOTES

Informative, not currently central to this project. 

- [Mistral Cookbook](https://github.com/mistralai/cookbook/): features examples contributed by our community and partners. If you have cool examples showcasing Mistral models, feel free to share them by submitting a PR to this repo.
- [Surya](https://github.com/VikParuchuri/surya): OCR and line detection in 90+ languages
- [Semantic Chunking](https://python.langchain.com/docs/modules/data_connection/document_transformers/semantic-chunker): Splits the text based on semantic similarity.
- [Take company docs. Chunk it. Ask ollama to create questions based on chunks](https://twitter.com/cto_junior/status/1752986228553650549) TDM (e/λ)
  > Ask ollama to answer the said questions based on chunks (done seperately to ensure verbose answer)\
  > Any embedding model to verify if the answer is def related to the chunk\
  > Maybe some keyword matches\
  > Pending step to remove further hallucinations (ask GPT-4/Mistral-medium to rate it from 1 to 5??)\
  > A decent dataset acquired
- [Tonic Validate x LlamaIndex: Implementing integration tests for LlamaIndex](https://www.llamaindex.ai/blog/tonic-validate-x-llamaindex-implementing-integration-tests-for-llamaindex-43db50b76ed9)
- [Building a Full-Stack Complex PDF AI chatbot w/ R.A.G (Llama Index)](https://www.youtube.com/watch?v=TOeAe8KB68E)
- [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory): Unify Efficient Fine-tuning of 100+ LLMs
- [Democratizing LLMs: 4-bit Quantization for Optimal LLM Inference](https://medium.com/towards-data-science/democratizing-llms-4-bit-quantization-for-optimal-llm-inference-be30cf4e0e34?sk=3c394a4eec9ad7744200a15e1c02fd83If): A deep dive into model quantization with GGUF and llama.cpp and model evaluation with LlamaIndex
- [🦎 LazyAxolotl](https://colab.research.google.com/drive/1TsDKNo2riwVmU55gjuBgB1AXVtRRfRHW): Large Language Model Course ❤️ Created by @maximelabonne.
  > This notebook allows you to fine-tune your LLMs using Axolotl and Runpod (please consider using my referral link).    It can also use LLM AutoEval to automatically evaluate the trained model using Nous' benchmark suite.    You can find Axolotl YAML configurations (SFT or DPO) on GitHub or Hugging Face.
- [Mastering PDFs: Extracting Sections, Headings, Paragraphs, and Tables with Cutting-Edge Parser](https://blog.llamaindex.ai/mastering-pdfs-extracting-sections-headings-paragraphs-and-tables-with-cutting-edge-parser-faea18870125)
- [Fine-Tuning Pretrained Models](https://ludwig.ai/latest/user_guide/distributed_training/finetuning/)
- [scipdf parser](https://github.com/titipata/scipdf_parser): Python PDF parser for scientific publications: content and figures 
- [Science Parse](https://github.com/allenai/science-parse) parses scientific papers (in PDF form) and returns them in structured form. 
- [Chunk Visualizer](https://huggingface.co/spaces/m-ric/chunk_visualizer) 
- https://github.com/topics/pdf-parsing
  - https://github.com/py-pdf/pypdf
  - https://github.com/jsvine/pdfplumber
- https://github.com/AymenKallala/RAG_Maestro
- [AirbyteLoader](https://python.langchain.com/docs/integrations/document_loaders/airbyte): Airbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases.
- https://github.com/yuhuixu1993/qa-lora
- https://github.com/modelscope/swift?tab=readme-ov-file#-getting-started
- https://github.com/ludwig-ai/ludwig/issues/3814
- https://colab.research.google.com/drive/1Dyauq4kTZoLewQ1cApceUQVNcnnNTzg_?usp=sharing
- https://github.com/unslothai/unsloth
- https://github.com/OpenAccess-AI-Collective/axolotl
- https://github.com/ggerganov/llama.cpp/tree/master/examples/finetune
- https://towardsdatascience.com/fine-tune-a-mistral-7b-model-with-direct-preference-optimization-708042745aac
- https://towardsdatascience.com/democratizing-llms-4-bit-quantization-for-optimal-llm-inference-be30cf4e0e34